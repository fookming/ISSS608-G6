{
  "hash": "2ba640fda76179086a14686bc9f9993b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Preparation\"\nauthor: \"Nguyen Bao Thu Phuong & Shreya Agarwal\"\ndate: \"18 March 2025\" \ndate-modified: \"last-modified\"\nexecute:\n  eval: true\n  echo: true\n  message: false\n  freeze: true\n  warning: false\n---\n\n\n\n\n\n# Overview\n\nData Preparation for final use\n\n## The Data\n\n-   Scraped weather data and weather stations records\n\n# Install R packages\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse)\n```\n:::\n\n\n\n\n\n# Data Wrangling\n\n## Data Import and Preparation\n\n### Daily Weather Records\n\nFirst we read in the daily weather records scraped from weather.gov.sg into tibble dataframe `climate_raw` using `read_csv()` .\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclimate_raw = read_csv(\"data/climate_historical_daily_records/Climate_Data_2015_2024.csv\")\n```\n:::\n\n\n\n\n\n### Weather Station Records\n\nWe only want to consider Full AWS stations since it contains data for all different weather parameters. Many other stations are classified as \"Close Stations\", \"Daily Rainfall Stations\" (only rainfall metrics) etc which we are not considering for our deeper analysis.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read station metadata and filter for Full AWS stations\nstation = read_csv(\"data/Station_Records.csv\") |> \n  filter(Station_Type == \"Full AWS Station\")\n```\n:::\n\n\n\n\n\nCheck duplicate\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nduplicate <- station %>%    \n  group_by_all() %>%    \n  filter(n()>1) %>%    \n  ungroup()\n\nduplicate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 0 × 5\n# ℹ 5 variables: Station <chr>, code <chr>, Lat <dbl>, Long <dbl>,\n#   Station_Type <chr>\n```\n\n\n:::\n:::\n\n\n\n\n\n## Data Wrangling\n\n### Join both tables\n\nFilter daily weather data for active AWS stations only and join the 2 datasets.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join to retain only Full AWS station records\nclimate = inner_join(station,climate_raw, by = \"Station\")\n```\n:::\n\n\n\n\n\nCheck for duplicates\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nduplicate <- climate %>%    \n  group_by_all() %>%    \n  filter(n()>1) %>%    \n  ungroup()    \n\nduplicate\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 0 × 17\n# ℹ 17 variables: Station <chr>, code <chr>, Lat <dbl>, Long <dbl>,\n#   Station_Type <chr>, Year <dbl>, Month <dbl>, Day <dbl>,\n#   Daily Rainfall Total (mm) <dbl>, Highest 30 min Rainfall (mm) <dbl>,\n#   Highest 60 min Rainfall (mm) <dbl>, Highest 120 min Rainfall (mm) <dbl>,\n#   Mean Temperature (Celsius) <dbl>, Maximum Temperature (Celsius) <dbl>,\n#   Minimum Temperature (Celsius) <dbl>, Mean Wind Speed (km/h) <dbl>,\n#   Max Wind Speed (km/h) <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n\nThe output shows there is no duplicate in `climate` dataframe.\n\n### Filter climate dataset for only key parameters\n\nNext we select only the relevant columns for our weather analysis\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select relevant columns\nclimate <- climate |> \n  select(Station, Station_Type, Year, Month, Day,\n         `Daily Rainfall Total (mm)`,\n         `Mean Temperature (Celsius)`,\n         `Maximum Temperature (Celsius)`,\n         `Minimum Temperature (Celsius)`,\n         `Mean Wind Speed (km/h)`)\n```\n:::\n\n\n\n\n\nNow we only have 10 columns and 5 weather parameters we want to further perform our analysis on.\n\n### Count months per station with missing values for Daily Rainfall\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count missing values for each Station, Year, and Month \nmissing_rain_counts <- climate %>%   \n  group_by(Station, Year, Month) %>%   \n  summarise(\n    `Missing Daily Rainfall Total` = sum(is.na(`Daily Rainfall Total (mm)`))   ) %>%  \n    # Exclude rows where all missing counts are zero\n  filter(`Missing Daily Rainfall Total` > 0) |>\n  ungroup()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count the number of months per station where missing days exceed 15 \nmissing_rain_summary <- missing_rain_counts %>%   \n  filter(`Missing Daily Rainfall Total` >= 15) %>%   \n  group_by(Station, Year) %>%   \n  summarise(Count_Months = n()) %>%   \n  arrange(Year)|>   \n  pivot_wider(names_from = Year, values_from = Count_Months) |>   \n  ungroup()\n```\n:::\n\n\n\n\n\nObservations - Rainfall has 7 stations with \\>15 days of missing data for months over the years. Also observed that some stations eg - Semakau Island has a full year of missing data record. 2015-2017 specially has a lot of missing data across stations.\n\n### Count months per station with missing values for Mean Temperature\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count missing values for each Station, Year, and Month \nmissing_temp_counts <- climate %>%   \n  group_by(Station, Year, Month) %>%   \n  summarise(     \n    `Missing Mean Temperature` = sum(is.na(`Mean Temperature (Celsius)`))) %>%   \n  # Exclude rows where all missing counts are zero\n  filter(`Missing Mean Temperature` > 0) |>\n  ungroup()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count the number of months per station where missing days exceed 15 \nmissing_temp_summary <- missing_temp_counts %>%    \n  filter(`Missing Mean Temperature` >= 15) %>%   \n  group_by(Station, Year) %>%   \n  summarise(Count_Months = n()) %>%   \n  arrange(Year)|>   \n  pivot_wider(names_from = Year, values_from = Count_Months) |>   \n  ungroup()\n```\n:::\n\n\n\n\n\nObservations - Those same 7 stations for daily rainfall are also part of the total 15 stations for Mean Temp with missing data where \\>15 days are missing per month. Also observed that some stations have full years of missing data record. And 2015-2017 specially has a lot of missing data across stations.\n\n### Filtering out stations with \\>=3 months of missing records from climate dataset\n\nAs observed above, we are only going to keep data from 2018 onwards considering the missing data for 2015-2017 time period. Then for each station we take the total count of missing months across the years and flag the stations with \\>=3 total count so that those flagged stations can be filtered out from our main climate dataset.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilter_invalid_stations <- function(summary_df, from_year = 2018) {\n  # Get only year columns ≥ from_year\n  year_cols <- summary_df |> \n    select(where(is.numeric)) |> \n    select(matches(\"^[0-9]{4}$\")) |> \n    select(as.character(from_year):last_col()) |> \n    colnames()\n\n  summary_df |> \n    rowwise() |> \n    mutate(total_flagged_months = sum(c_across(all_of(year_cols)), na.rm = TRUE)) |> \n    filter(total_flagged_months >= 3) |> \n    pull(Station)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get invalid stations (stations to exclude)\ninvalid_rain_stations <- filter_invalid_stations(missing_rain_summary)\ninvalid_temp_stations <- filter_invalid_stations(missing_temp_summary)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Combine all stations to exclude\nstations_to_exclude <- union(invalid_rain_stations, invalid_temp_stations) \n```\n:::\n\n\n\n\n\nThere are total 5 stations which will be excluded. Applying this filter on the climate dataset.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Now filter the full dataset to only include stations from 2018-2024\nclimate_final <- climate |> \n  filter(!(Station %in% stations_to_exclude), Year >= 2018, Year <= 2024)\n\nsummary(climate_final)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Station          Station_Type            Year          Month       \n Length:38186       Length:38186       Min.   :2018   Min.   : 1.000  \n Class :character   Class :character   1st Qu.:2019   1st Qu.: 4.000  \n Mode  :character   Mode  :character   Median :2021   Median : 7.000  \n                                       Mean   :2021   Mean   : 6.529  \n                                       3rd Qu.:2023   3rd Qu.:10.000  \n                                       Max.   :2024   Max.   :12.000  \n                                                                      \n      Day        Daily Rainfall Total (mm) Mean Temperature (Celsius)\n Min.   : 1.00   Min.   :  0.000           Min.   :22.20             \n 1st Qu.: 8.00   1st Qu.:  0.000           1st Qu.:27.30             \n Median :16.00   Median :  0.200           Median :28.10             \n Mean   :15.73   Mean   :  6.868           Mean   :28.05             \n 3rd Qu.:23.00   3rd Qu.:  6.600           3rd Qu.:28.90             \n Max.   :31.00   Max.   :210.600           Max.   :31.70             \n                 NA's   :260               NA's   :571               \n Maximum Temperature (Celsius) Minimum Temperature (Celsius)\n Min.   :22.80                 Min.   :20.40                \n 1st Qu.:30.80                 1st Qu.:24.40                \n Median :32.00                 Median :25.40                \n Mean   :31.79                 Mean   :25.46                \n 3rd Qu.:33.00                 3rd Qu.:26.50                \n Max.   :38.00                 Max.   :29.70                \n NA's   :483                   NA's   :487                  \n Mean Wind Speed (km/h)\n Min.   : 0.400        \n 1st Qu.: 5.600        \n Median : 7.600        \n Mean   : 8.474        \n 3rd Qu.:10.400        \n Max.   :31.300        \n NA's   :1701          \n```\n\n\n:::\n:::\n\n\n\n\n\nBelow is the list of the final 15 AWS stations that we will be focusing our analysis on.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclimate_final %>% \n  distinct(Station) %>% \n  arrange(Station) %>% \n  mutate(Station_ID = row_number())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 × 2\n   Station               Station_ID\n   <chr>                      <int>\n 1 Admiralty                      1\n 2 Ang Mo Kio                     2\n 3 Changi                         3\n 4 Choa Chu Kang (South)          4\n 5 Clementi                       5\n 6 East Coast Parkway             6\n 7 Jurong (West)                  7\n 8 Jurong Island                  8\n 9 Newton                         9\n10 Pasir Panjang                 10\n11 Paya Lebar                    11\n12 Pulau Ubin                    12\n13 Sentosa Island                13\n14 Tai Seng                      14\n15 Tuas South                    15\n```\n\n\n:::\n:::\n\n\n\n\n\nSaving the final dataset.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Save the full final cleaned dataset\n# write_csv(climate_final, \"data/climate_historical_daily_records/climate_final_2018_2024.csv\")\n```\n:::\n\n\n\n\n\n## Replacing Missing Values\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}