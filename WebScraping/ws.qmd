---
title: "Web Scraping"
author: "Ee Fook Ming"
---

```{r}
pacman::p_load(httr, readxl, dplyr, readr)
```

```{r}
station_records <- read_excel("data/Station_Records.xlsx")

# Obtain a list of station codes
station_codes <- station_records$`code`
station_type <- station_records$`Station_Type`

print(station_codes)
```

```{r}
print(station_type)
```

The code chunk retrieves station codes and their corresponding types. These codes form part of a text string used to construct hyperlinks, which retrieve data directly from the weather website. There are three station types:

Full AWS station: collects weather data on rainfall, temperature, and wind. Rainfall station: collects rainfall data only. Closed station: a station that is no longer operational. These station identifiers are useful for data filtering, analysis, and visualization based on specific station characteristics.

```{r}
#| eval: false

library(httr)
library(readr)

# Set base URL template and save file path
base_url_template <- "http://www.weather.gov.sg/files/dailydata/DAILYDATA_%s_%d%s.csv"
save_file <- "data/climate_historical_daily_records/Climate_Data_2015_2024_v4.csv"
dir.create(dirname(save_file), recursive = TRUE, showWarnings = FALSE)

# Define expected column names (preserve exact spacing)
column_names <- c(
  "Station", "Year", "Month", "Day", 
  "Daily Rainfall Total (mm)", "Highest 30 min Rainfall (mm)", 
  "Highest 60 min Rainfall (mm)", "Highest 120 min Rainfall (mm)", 
  "Mean Temperature (C)", "Maximum Temperature (C)", 
  "Minimum Temperature (C)", "Mean Wind Speed (km/h)", 
  "Max Wind Speed (km/h)"
)

# Ensure CSV file has proper headers only if it does not exist
if (!file.exists(save_file)) {
  write.table(data.frame(matrix(ncol = length(column_names), nrow = 0, dimnames = list(NULL, column_names))),
              save_file, sep = ",", row.names = FALSE, col.names = TRUE, quote = FALSE)
}

# Function to download and append data
download_and_append <- function(station_code, year, month) {
  month_str <- sprintf("%02d", month)  # Format month as "01", "02", etc.
  file_url <- sprintf(base_url_template, station_code, year, month_str)

  response <- tryCatch({
    GET(file_url)
  }, error = function(e) {
    message(sprintf("Error fetching: %s", file_url))
    return(NULL)
  })

  if (!is.null(response) && status_code(response) == 200) {
    # Read CSV content without modifying column names
    csv_data <- tryCatch({
      read_csv(content(response, "raw"), show_col_types = FALSE, col_names = FALSE, skip = 1, check.names = FALSE)
    }, error = function(e) {
      message(sprintf("Failed to read CSV: %s", file_url))
      return(NULL)
    })

    # Ensure correct column alignment and remove empty rows
    if (!is.null(csv_data) && ncol(csv_data) == length(column_names)) {
      colnames(csv_data) <- column_names  # Assign exact column names

      csv_data <- csv_data[rowSums(is.na(csv_data) | csv_data == "") < ncol(csv_data), ]  # Remove empty rows
      
      if (nrow(csv_data) > 0) {
        write.table(csv_data, save_file, sep = ",", row.names = FALSE, col.names = FALSE, append = TRUE, quote = FALSE)
        message(sprintf("Appended data for %s - %d-%s", station_code, year, month_str))
      } else {
        message(sprintf("Skipping empty dataset: %s", file_url))
      }
    } else {
      message(sprintf("Data format mismatch: %s", file_url))
    }
  } else {
    message(sprintf("Failed to download: %s", file_url))
  }
}

# Loop through each station code and fetch data
for (station_code in station_codes) {
  for (year in 2015:2024) {
    for (month in 1:12) {
      download_and_append(station_code, year, month)
    }
  }
}

print("Download process completed for all stations.")



```

The code chunk systematically downloads daily climate data from Singaporeâ€™s weather service for multiple weather stations, covering years 2015 through 2024. It constructs URLs dynamically based on station codes, year, and month, retrieves CSV files, filters out incomplete or invalid entries, and then consolidates valid data into a single CSV file (Climate_Data_2015_2024_v4.csv). The primary intention is to compile a structured, comprehensive dataset of climate measurements for subsequent data processing, analysis or visualization tasks.
