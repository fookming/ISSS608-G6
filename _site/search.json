[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "The Team",
    "section": "",
    "text": "We developed this project for ISSS608 (Visual Analytics and Applications) course of Masters of IT in Business (MITB) in Singapore Management University under the guidance of Dr. Kam Tin Seong, Associate Professor of Information Systems during the Academic Year 2024-25.\nMembers\n\nEe Fook Ming\nNguyen Bao Thu Phuong\nShreya Agarwal"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "WeatherWise Singapore",
    "section": "",
    "text": "1 Motivation\nSingapore’s tropical climate creates frequent and intense weather variations, which significantly impact sectors like urban planning, insurance, agriculture, and infrastructure. However, current weather platforms fall short in supporting data-driven decision-making due to:\n\nBasic Functionality: Existing dashboards offer only real-time observations and short-term forecasts.\nNo Advanced Analytics: Lack of tools like trend forecasting, anomaly detection, and predictive modeling.\nLimited Historical Insights: Inability to analyze long-term climate trends or generate custom comparisons.\n\nThese factors signify a need for a comprehensive platform offering statistical insights, spatial visualizations, and predictive modeling of Singapore weather measurements.\n\n\n2 Objectives\nOur project tackles this challenge by offering a platform with rich analytics, interactive visualizations, and predictive tools tailored to Singapore’s context. This empowers businesses, researchers, and policymakers to make timely, strategic, and informed decisions, contributing to national climate resilience and smarter urban development.The project focuses on three main objectives:\n\nBuild a Comprehensive Weather Analytics Platform: Integrate historical weather data from the Meteorological Service Singapore; covering temperature, rainfall, and wind, organized by station and time for easy access and analysis.\nDevelop Advanced Visual Analytics: Offer interactive time series and geospatial visualizations—such as trend lines, heat maps, forecasting, and spatial interpolation - using robust statistical techniques to uncover patterns, anomalies, and future conditions in Singapore’s weather.\nEnsure Independent and Flexible Use Across Sectors: Design a user-friendly platform that supports diverse stakeholders - businesses, academics, and government agencies - with decision-making and strategic planning based on their unique needs.\n\n\n\n3 Main Features\nThe final WeatherWise SG Shiny Application consists of three core modules:\n\nTime Series Data Analysis: Exploratory and Confirmatory Data Analysis\n\nExploratory and comparative data analysis to uncover trends in temperature, rainfall, and wind across regions and seasons.\nVisualization of seasonal/weather trends and inter-region comparisons.\nStatistical tests for station-wise comparison across different time intervals and parameters.\n\nTime Series Forecasting\n\nSTL: Split data into trend, seasonal and residuals.\nACF/PACF: Identify lags to set ARIMA/SARIMA p, q parameters.\nADF Test: Check stationary and fine tune ARIMA/SARIMA (p,d,q)(P,D,Q).\nBenchmarking: Compare with other models – Prophet and ETS; evaluate different models using MAE, RMSE, MAPE.\n\nGeospatial Analysis\n\nPlot extreme weather events by station on Singapore map.\nInterpolate weather conditions at unmeasured locations based on nearby data points using Inverse Distance Weighted (IDW) and Kriging methods."
  },
  {
    "objectID": "Proposal/Proposal.html",
    "href": "Proposal/Proposal.html",
    "title": "Singapore Weather Analytics",
    "section": "",
    "text": "Singapore’s tropical climate, characterized by high temperatures, humidity, and intense rainfall, presents significant environmental and operational challenges across various sectors. Industries such as urban planning, real estate, insurance, agriculture, and infrastructure management require accurate and real-time weather analytics to make data-driven decisions and mitigate climate-related risks.\nHowever, existing weather dashboards offer limited insights, focusing primarily on basic real-time observations without deep analytical capabilities, trend forecasting, or business-context integration. This project aims to address these gaps by developing a comprehensive, standalone weather analytics platform tailored to Singapore’s unique climate conditions.\nAdditionally, the platform will incorporate robust statistical methods, spatial visualizations, and advanced predictive modelling tools. These analytical capabilities will empower businesses, researchers, and policymakers to independently derive actionable insights, thereby enhancing strategic climate resilience decision-making. By balancing specialized climate data provision with generalized applicability, the platform will serve diverse informational needs without being restricted to any specific industry."
  },
  {
    "objectID": "Proposal/Proposal.html#data-wrangling",
    "href": "Proposal/Proposal.html#data-wrangling",
    "title": "Singapore Weather Analytics",
    "section": "5.1 Data Wrangling",
    "text": "5.1 Data Wrangling\n\n5.1.1 Aspatial Data -\n\nData Collection & Merging: Scrape historical weather data from the MSS website for each location, month, and year from 2015 to 2024 and combine individual records into a single CSV file for unified analysis. \nFiltering Locations: Identify and retain only key locations in Singapore with consistent data availability. \nHandling Missing Values: Apply suitable imputation methods such as moving average or interpolation. \nDuplicate Removal: Identify and eliminate any duplicate entries to ensure data integrity. \nData Formatting: Standardize variable names, data types, and ensure proper date-time formats. \nOutlier Detection: Identify potential anomalies in temperature, rainfall, or wind speed that may indicate data inconsistencies. \nData Validation: Cross-check aggregated data against expected trends to confirm accuracy before analysis. \n\n\n\n5.1.2 Geospatial Data -\n\nCoordinate System Validation: Check if the correct EPSG code is assigned to the simple feature dataframe, and assign the correct EPSG code if applicable \nCoordinate System Projection: Transform the sf dataframe from geographic coordinate system to projected coordinate system for futher calculations. \nStandardize Naming Convention: Identify different naming conventions between Weather datafame Location and the Subzone dataframe Planning Area and standardize to common naming. \nData Join: Left join the Subzone planning dataframe with the Weather dataframe to bring in weather related information while keeping the dataframe as simple features."
  },
  {
    "objectID": "Proposal/Proposal.html#analytic-techniques--",
    "href": "Proposal/Proposal.html#analytic-techniques--",
    "title": "Singapore Weather Analytics",
    "section": "2 Analytic Techniques -",
    "text": "2 Analytic Techniques -\n\n2.1 Exploratory Data Analysis\n\n\n2.2 Time Series Analysis and Forecasting\n\n\n2.3 Geo-spatial Analysis"
  },
  {
    "objectID": "Proposal/Proposal.html#analytic-techniques",
    "href": "Proposal/Proposal.html#analytic-techniques",
    "title": "Singapore Weather Analytics",
    "section": "5.2 Analytic Techniques",
    "text": "5.2 Analytic Techniques\n\n5.2.1 Exploratory Data Analysis (EDA) & Comparative Data Analysis (CDA) -\n\nVisualizing Distribution & Trends: Generate histograms, boxplots, and density plots to analyze the distribution of temperature, rainfall, and wind speed over the years. \nComparative Analysis Across Locations & Time Periods: Compare weather patterns between different regions in Singapore and across different seasons. \nCorrelation Analysis: Examine relationships between variables, such as how temperature fluctuations correspond with wind speed or rainfall intensity. \n\n\n\n5.2.2 Time Series Analysis & Forecasting -\n\nTrend & Seasonality Detection: Use rolling averages, visual and seasonal plots to analyze long-term trends and seasonal variations in temperature, rainfall, and wind patterns. \nTime Series Decomposition: Apply statistical techniques like decomposition to separate trends, seasonality, and residuals. \nStatistical Analysis of Weather Patterns: Calculate key metrics such as mean temperature shifts, variance in rainfall, and wind speed fluctuations over time. \nForecasting Future Trends: Utilize models such as ARIMA, Prophet or Exponential Smoothing to project future weather trends and assess potential climate risks. \n\n\n\n5.2.3 Geo-spatial Analysis -\n\nSpatial Pattern Detection: Identifying Clusters in Weather Metrics\n\nIdentifying regions where neighboring locations exhibit consistently high rainfall or elevated temperatures, which may indicate localized climatic effects. \nDetecting spatial dependencies in wind speed, helping to understand airflow patterns across the city. \n\nSpatial Autocorrelation Analysis: Detecting Weather Trends and Anomalies\nSpatial autocorrelation techniques will be used to identify relationships between weather conditions at different locations and assess whether similar values cluster together. We will perform two key analyses: \n\nLocal Indicator of Spatial Association (LISA): Identifies statistically significant clusters or outliers where weather conditions deviate from surrounding locations. \nEmerging Hot Spot Analysis (EHSA): Identify persistent hot spots (regions where temperature or rainfall remains high) and cold spots (regions with consistently low values), highlight locations with shifting weather patterns. \n\nSpatial Interpolation and Geographically Weighted Predictive Modeling for Weather Forecasting:\n\nInterpolate weather conditions at unmeasured locations based on nearby data points using distance weight and Kriging method \nDerive predictive models incorporate both temporal and spatial dependencies using Geographically Weighted Random Forest."
  },
  {
    "objectID": "WebScraping/sma-5day.html",
    "href": "WebScraping/sma-5day.html",
    "title": "Climate Data Imputation using 5-Day SMA",
    "section": "",
    "text": "1 Load Libraries\n\npacman::p_load(tidyverse,dplyr, readr, openxlsx, zoo)\n\n\n\n2 5-Day\n\nlibrary(dplyr)\nlibrary(readr)\nlibrary(openxlsx)\n\n# === Load dataset ===\nclimate &lt;- read_csv(\"data/climate_historical_daily_records/climate_final_2018_2024.csv\")\noriginal &lt;- climate\n\n# === Columns to impute ===\nimpute_cols &lt;- c(\"Daily Rainfall Total (mm)\",\n                 \"Mean Temperature (Celsius)\",\n                 \"Maximum Temperature (Celsius)\",\n                 \"Minimum Temperature (Celsius)\",\n                 \"Mean Wind Speed (km/h)\")\n\n# === Backward SMA-5 for first 4 rows ===\n# === Backward SMA-5 (recursive fill for rows 4 to 1) ===\nfor (i in 4:1) {\n  window &lt;- climate[(i + 1):(i + 5), impute_cols]\n  sma_values &lt;- colMeans(window, na.rm = TRUE) %&gt;% round(1)\n  climate[i, impute_cols] &lt;- as.list(sma_values)\n}\n\n\n# === Forward SMA-5 for all other NAs ===\nfor (col in impute_cols) {\n  na_indices &lt;- which(is.na(climate[[col]]))\n  for (idx in na_indices) {\n    if (idx &gt;= 5) {\n      sma_val &lt;- mean(climate[[col]][(idx - 5):(idx - 1)], na.rm = TRUE) %&gt;% round(1)\n      if (!is.nan(sma_val)) {\n        climate[[col]][idx] &lt;- sma_val\n      }\n    }\n  }\n}\n\n# === Save updated CSV ===\nwrite_csv(climate, \"data/climate_historical_daily_records/climate_final_2018_2024_5-Day.csv\")\n\n# === Prepare Excel with bold + red styling for updated NA values ===\nwb &lt;- createWorkbook()\naddWorksheet(wb, \"Updated_NAs\")\n\n# Create red bold style\nstyle_red_bold &lt;- createStyle(textDecoration = \"bold\", fontColour = \"#FF0000\")\n\n# Write correct header row in row 1\nwriteData(wb, \"Updated_NAs\", as.data.frame(t(colnames(climate))), startRow = 1, colNames = FALSE)\n\n# Write entire dataset starting from row 2\nwriteData(wb, \"Updated_NAs\", climate, startRow = 2, colNames = FALSE)\n\n# Apply red + bold style for every updated NA field\nfor (col_name in impute_cols) {\n  col_idx &lt;- which(names(climate) == col_name)\n  updated_rows &lt;- which(is.na(original[[col_name]]) & !is.na(climate[[col_name]]))\n\n  if (length(updated_rows) &gt; 0) {\n    for (row in updated_rows) {\n      addStyle(wb,\n               sheet = \"Updated_NAs\",\n               style = style_red_bold,\n               rows = row + 1,   # Offset +1 because header is row 1\n               cols = col_idx,\n               gridExpand = FALSE,\n               stack = TRUE)\n    }\n  }\n}\n\n# Save Excel\nsaveWorkbook(wb, \"data/climate_historical_daily_records/NAs_fields_updated_5-Day.xlsx\", overwrite = TRUE)"
  },
  {
    "objectID": "WebScraping/ws.html",
    "href": "WebScraping/ws.html",
    "title": "Web Scraping",
    "section": "",
    "text": "pacman::p_load(httr, readxl, dplyr, readr)\n\n\nstation_records &lt;- read_excel(\"data/Station_Records.xlsx\")\n\n# Obtain a list of station codes\nstation_codes &lt;- station_records$`code`\nstation_type &lt;- station_records$`Station_Type`\n\nprint(station_codes)\n\n [1] \"S104\" \"S105\" \"S109\" \"S86\"  \"S63\"  \"S120\" \"S55\"  \"S64\"  \"S90\"  \"S92\" \n[11] \"S61\"  \"S24\"  \"S114\" \"S121\" \"S11\"  \"S50\"  \"S118\" \"S107\" \"S39\"  \"S101\"\n[21] \"S44\"  \"S117\" \"S33\"  \"S31\"  \"S71\"  \"S122\" \"S66\"  \"S112\" \"S08\"  \"S07\" \n[31] \"S40\"  \"S108\" \"S113\" \"S111\" \"S119\" \"S116\" \"S29\"  \"S94\"  \"S06\"  \"S106\"\n[41] \"S81\"  \"S77\"  \"S25\"  \"S102\" \"S80\"  \"S60\"  \"S36\"  \"S110\" \"S84\"  \"S79\" \n[51] \"S43\"  \"S78\"  \"S72\"  \"S23\"  \"S88\"  \"S89\"  \"S115\" \"S82\"  \"S35\"  \"S69\" \n[61] \"S46\"  \"S123\" \"S91\" \n\n\n\nprint(station_type)\n\n [1] \"Full AWS Station\" \"Closed Station\"   \"Full AWS Station\" \"Closed Station\"  \n [5] \"Closed Station\"   \"Rainfall Station\" \"Closed Station\"   \"Rainfall Station\"\n [9] \"Rainfall Station\" \"Rainfall Station\" \"Closed Station\"   \"Full AWS Station\"\n[13] \"Rainfall Station\" \"Full AWS Station\" \"Closed Station\"   \"Full AWS Station\"\n[17] \"Closed Station\"   \"Full AWS Station\" \"Closed Station\"   \"Closed Station\"  \n[21] \"Full AWS Station\" \"Full AWS Station\" \"Rainfall Station\" \"Closed Station\"  \n[25] \"Rainfall Station\" \"Closed Station\"   \"Rainfall Station\" \"Rainfall Station\"\n[29] \"Rainfall Station\" \"Rainfall Station\" \"Rainfall Station\" \"Full AWS Station\"\n[33] \"Rainfall Station\" \"Full AWS Station\" \"Rainfall Station\" \"Full AWS Station\"\n[37] \"Rainfall Station\" \"Rainfall Station\" \"Full AWS Station\" \"Full AWS Station\"\n[41] \"Rainfall Station\" \"Rainfall Station\" \"Full AWS Station\" \"Full AWS Station\"\n[45] \"Full AWS Station\" \"Full AWS Station\" \"Rainfall Station\" \"Closed Station\"  \n[49] \"Rainfall Station\" \"Rainfall Station\" \"Full AWS Station\" \"Rainfall Station\"\n[53] \"Closed Station\"   \"Full AWS Station\" \"Rainfall Station\" \"Rainfall Station\"\n[57] \"Full AWS Station\" \"Closed Station\"   \"Closed Station\"   \"Closed Station\"  \n[61] \"Closed Station\"   \"Closed Station\"   \"Closed Station\"  \n\n\nThe code chunk retrieves station codes and their corresponding types. These codes form part of a text string used to construct hyperlinks, which retrieve data directly from the weather website. There are three station types:\nFull AWS station: collects weather data on rainfall, temperature, and wind. Rainfall station: collects rainfall data only. Closed station: a station that is no longer operational. These station identifiers are useful for data filtering, analysis, and visualization based on specific station characteristics.\n\nlibrary(httr)\nlibrary(readr)\n\n# Set base URL template and save file path\nbase_url_template &lt;- \"http://www.weather.gov.sg/files/dailydata/DAILYDATA_%s_%d%s.csv\"\nsave_file &lt;- \"data/climate_historical_daily_records/Climate_Data_2015_2024_v4.csv\"\ndir.create(dirname(save_file), recursive = TRUE, showWarnings = FALSE)\n\n# Define expected column names (preserve exact spacing)\ncolumn_names &lt;- c(\n  \"Station\", \"Year\", \"Month\", \"Day\", \n  \"Daily Rainfall Total (mm)\", \"Highest 30 min Rainfall (mm)\", \n  \"Highest 60 min Rainfall (mm)\", \"Highest 120 min Rainfall (mm)\", \n  \"Mean Temperature (C)\", \"Maximum Temperature (C)\", \n  \"Minimum Temperature (C)\", \"Mean Wind Speed (km/h)\", \n  \"Max Wind Speed (km/h)\"\n)\n\n# Ensure CSV file has proper headers only if it does not exist\nif (!file.exists(save_file)) {\n  write.table(data.frame(matrix(ncol = length(column_names), nrow = 0, dimnames = list(NULL, column_names))),\n              save_file, sep = \",\", row.names = FALSE, col.names = TRUE, quote = FALSE)\n}\n\n# Function to download and append data\ndownload_and_append &lt;- function(station_code, year, month) {\n  month_str &lt;- sprintf(\"%02d\", month)  # Format month as \"01\", \"02\", etc.\n  file_url &lt;- sprintf(base_url_template, station_code, year, month_str)\n\n  response &lt;- tryCatch({\n    GET(file_url)\n  }, error = function(e) {\n    message(sprintf(\"Error fetching: %s\", file_url))\n    return(NULL)\n  })\n\n  if (!is.null(response) && status_code(response) == 200) {\n    # Read CSV content without modifying column names\n    csv_data &lt;- tryCatch({\n      read_csv(content(response, \"raw\"), show_col_types = FALSE, col_names = FALSE, skip = 1, check.names = FALSE)\n    }, error = function(e) {\n      message(sprintf(\"Failed to read CSV: %s\", file_url))\n      return(NULL)\n    })\n\n    # Ensure correct column alignment and remove empty rows\n    if (!is.null(csv_data) && ncol(csv_data) == length(column_names)) {\n      colnames(csv_data) &lt;- column_names  # Assign exact column names\n\n      csv_data &lt;- csv_data[rowSums(is.na(csv_data) | csv_data == \"\") &lt; ncol(csv_data), ]  # Remove empty rows\n      \n      if (nrow(csv_data) &gt; 0) {\n        write.table(csv_data, save_file, sep = \",\", row.names = FALSE, col.names = FALSE, append = TRUE, quote = FALSE)\n        message(sprintf(\"Appended data for %s - %d-%s\", station_code, year, month_str))\n      } else {\n        message(sprintf(\"Skipping empty dataset: %s\", file_url))\n      }\n    } else {\n      message(sprintf(\"Data format mismatch: %s\", file_url))\n    }\n  } else {\n    message(sprintf(\"Failed to download: %s\", file_url))\n  }\n}\n\n# Loop through each station code and fetch data\nfor (station_code in station_codes) {\n  for (year in 2015:2024) {\n    for (month in 1:12) {\n      download_and_append(station_code, year, month)\n    }\n  }\n}\n\nprint(\"Download process completed for all stations.\")\n\nThe code chunk systematically downloads daily climate data from Singapore’s weather service for multiple weather stations, covering years 2015 through 2024. It constructs URLs dynamically based on station codes, year, and month, retrieves CSV files, filters out incomplete or invalid entries, and then consolidates valid data into a single CSV file (Climate_Data_2015_2024_v4.csv). The primary intention is to compile a structured, comprehensive dataset of climate measurements for subsequent data processing, analysis or visualization tasks."
  },
  {
    "objectID": "Shiny-App/WeatherWiseSG-EFM/landing_page.html#exploratory-data-analysis-eda-comparative-data-analysis-cda",
    "href": "Shiny-App/WeatherWiseSG-EFM/landing_page.html#exploratory-data-analysis-eda-comparative-data-analysis-cda",
    "title": "Singapore Weather Dashboard",
    "section": "Exploratory Data Analysis (EDA) & Comparative Data Analysis (CDA)",
    "text": "Exploratory Data Analysis (EDA) & Comparative Data Analysis (CDA)\nThis section focuses on analyzing the distribution and trends of weather variables such as temperature, rainfall, and wind speed through visual tools like histograms and density plots. It also facilitates comparative analysis across different regions in Singapore and time periods, allowing users to observe seasonal differences. Additionally, it explores the relationships between variables, such as the correlation between temperature changes and rainfall or wind speed."
  },
  {
    "objectID": "Shiny-App/WeatherWiseSG-EFM/landing_page.html#time-series-analysis-forecasting",
    "href": "Shiny-App/WeatherWiseSG-EFM/landing_page.html#time-series-analysis-forecasting",
    "title": "Singapore Weather Dashboard",
    "section": "Time Series Analysis & Forecasting",
    "text": "Time Series Analysis & Forecasting\nThis section identifies long-term and seasonal patterns in weather data using rolling averages and seasonal plots. It includes decomposition techniques to separate trend, seasonality, and residuals, enabling a deeper understanding of climatic dynamics. Users can statistically analyze weather fluctuations and forecast future trends using models like ARIMA, Prophet, or Exponential Smoothing to assess future climate risks and variations."
  },
  {
    "objectID": "Shiny-App/WeatherWiseSG-EFM/landing_page.html#geo-spatial-analysis",
    "href": "Shiny-App/WeatherWiseSG-EFM/landing_page.html#geo-spatial-analysis",
    "title": "Singapore Weather Dashboard",
    "section": "Geo-spatial Analysis",
    "text": "Geo-spatial Analysis\nThis module detects spatial patterns and dependencies in weather metrics across Singapore. It identifies clusters of high or low values in temperature, rainfall, or wind speed, which may indicate localized climatic phenomena. Spatial autocorrelation methods are utilized to detect significant anomalies or hot-spots. Additionally, spatial interpolation and geographically weighted predictive models are used to forecast weather conditions at unmeasured locations, integrating both distance-based and machine learning approaches."
  },
  {
    "objectID": "WebScraping/Data_Scraping.html",
    "href": "WebScraping/Data_Scraping.html",
    "title": "Web Scraping",
    "section": "",
    "text": "1 Climate Historical Daily Records\nAs the climate historical daily records can only be retrieved from Meteorological Service Singapore for a specific month of one station at a time, we have written the below code chunk to retrieve all climate daily records from 2015-2024 and compiled into one single csv file.\n\n\n2 Set up R environment\nFor the purpose of data scraping and compiling, the following packages are installed and loaded into R environment using p_load() of pacman package.\n\npacman::p_load(httr, readxl, dplyr, readr)\n\n\n\n3 Download Data\nFirst we read in the Station_Records.xlsx using below code chunk to retrieve station codes and their corresponding types. The station codes form part of a text string used to construct hyperlinks, which retrieve data directly from the weather website.\n\nstation_records &lt;- read_excel(\"data/Station_Records.xlsx\")\n\n# Obtain a list of station codes\nstation_codes &lt;- station_records$`code`\nstation_type &lt;- station_records$`Station_Type`\n\nprint(station_codes)\n\n [1] \"S104\" \"S105\" \"S109\" \"S86\"  \"S63\"  \"S120\" \"S55\"  \"S64\"  \"S90\"  \"S92\" \n[11] \"S61\"  \"S24\"  \"S114\" \"S121\" \"S11\"  \"S50\"  \"S118\" \"S107\" \"S39\"  \"S101\"\n[21] \"S44\"  \"S117\" \"S33\"  \"S31\"  \"S71\"  \"S122\" \"S66\"  \"S112\" \"S08\"  \"S07\" \n[31] \"S40\"  \"S108\" \"S113\" \"S111\" \"S119\" \"S116\" \"S29\"  \"S94\"  \"S06\"  \"S106\"\n[41] \"S81\"  \"S77\"  \"S25\"  \"S102\" \"S80\"  \"S60\"  \"S36\"  \"S110\" \"S84\"  \"S79\" \n[51] \"S43\"  \"S78\"  \"S72\"  \"S23\"  \"S88\"  \"S89\"  \"S115\" \"S82\"  \"S35\"  \"S69\" \n[61] \"S46\"  \"S123\" \"S91\" \n\n\n\nprint(unique(station_type))\n\n[1] \"Full AWS Station\" \"Closed Station\"   \"Rainfall Station\"\n\n\nThe output shows there are three station types:\n\nFull AWS station: collects weather data on rainfall, temperature, and wind.\nRainfall station: collects rainfall data only.\nClosed station: a station that is no longer operational.\n\nThese station identifiers are useful for data filtering, analysis, and visualization based on specific station characteristics.\nThe below code chunk systematically downloads daily climate data from Singapore’s weather service for all weather stations, covering years 2015 through 2024. It constructs URLs dynamically based on station codes, year, and month, retrieves CSV files, filters out incomplete or invalid entries, and then consolidates valid data into a single CSV file (Climate_Data_2015_2024_v4.csv). The primary intention is to compile a structured, comprehensive dataset of climate measurements for subsequent data processing, analysis or visualization tasks.\n\nlibrary(httr)\nlibrary(readr)\n\n# Set base URL template and save file path\nbase_url_template &lt;- \"http://www.weather.gov.sg/files/dailydata/DAILYDATA_%s_%d%s.csv\"\nsave_file &lt;- \"data/climate_historical_daily_records/Climate_Data_2015_2024_v4.csv\"\ndir.create(dirname(save_file), recursive = TRUE, showWarnings = FALSE)\n\n# Define expected column names (preserve exact spacing)\ncolumn_names &lt;- c(\n  \"Station\", \"Year\", \"Month\", \"Day\", \n  \"Daily Rainfall Total (mm)\", \"Highest 30 min Rainfall (mm)\", \n  \"Highest 60 min Rainfall (mm)\", \"Highest 120 min Rainfall (mm)\", \n  \"Mean Temperature (C)\", \"Maximum Temperature (C)\", \n  \"Minimum Temperature (C)\", \"Mean Wind Speed (km/h)\", \n  \"Max Wind Speed (km/h)\"\n)\n\n# Ensure CSV file has proper headers only if it does not exist\nif (!file.exists(save_file)) {\n  write.table(data.frame(matrix(ncol = length(column_names), nrow = 0, dimnames = list(NULL, column_names))),\n              save_file, sep = \",\", row.names = FALSE, col.names = TRUE, quote = FALSE)\n}\n\n# Function to download and append data\ndownload_and_append &lt;- function(station_code, year, month) {\n  month_str &lt;- sprintf(\"%02d\", month)  # Format month as \"01\", \"02\", etc.\n  file_url &lt;- sprintf(base_url_template, station_code, year, month_str)\n\n  response &lt;- tryCatch({\n    GET(file_url)\n  }, error = function(e) {\n    message(sprintf(\"Error fetching: %s\", file_url))\n    return(NULL)\n  })\n\n  if (!is.null(response) && status_code(response) == 200) {\n    # Read CSV content without modifying column names\n    csv_data &lt;- tryCatch({\n      read_csv(content(response, \"raw\"), show_col_types = FALSE, col_names = FALSE, skip = 1, check.names = FALSE)\n    }, error = function(e) {\n      message(sprintf(\"Failed to read CSV: %s\", file_url))\n      return(NULL)\n    })\n\n    # Ensure correct column alignment and remove empty rows\n    if (!is.null(csv_data) && ncol(csv_data) == length(column_names)) {\n      colnames(csv_data) &lt;- column_names  # Assign exact column names\n\n      csv_data &lt;- csv_data[rowSums(is.na(csv_data) | csv_data == \"\") &lt; ncol(csv_data), ]  # Remove empty rows\n      \n      if (nrow(csv_data) &gt; 0) {\n        write.table(csv_data, save_file, sep = \",\", row.names = FALSE, col.names = FALSE, append = TRUE, quote = FALSE)\n        message(sprintf(\"Appended data for %s - %d-%s\", station_code, year, month_str))\n      } else {\n        message(sprintf(\"Skipping empty dataset: %s\", file_url))\n      }\n    } else {\n      message(sprintf(\"Data format mismatch: %s\", file_url))\n    }\n  } else {\n    message(sprintf(\"Failed to download: %s\", file_url))\n  }\n}\n\n# Loop through each station code and fetch data\nfor (station_code in station_codes) {\n  for (year in 2015:2024) {\n    for (month in 1:12) {\n      download_and_append(station_code, year, month)\n    }\n  }\n}\n\nprint(\"Download process completed for all stations.\")"
  },
  {
    "objectID": "WebScraping/Data_Preparation.html",
    "href": "WebScraping/Data_Preparation.html",
    "title": "Data Preparation",
    "section": "",
    "text": "This section outlines the data preparation process, including the exclusion of stations with extensive missing data and the imputation of missing values for selected stations, ensuring data quality for subsequent visual analytics in our project.\n\n\n\nScraped weather data from Meteorological Service Singapore stored in Climate_Data_2015_2024.csv .\nWeather Station records from weather.gov.sg, stored in Station_Records.csv ."
  },
  {
    "objectID": "WebScraping/Data_Preparation.html#the-data",
    "href": "WebScraping/Data_Preparation.html#the-data",
    "title": "Data Preparation",
    "section": "",
    "text": "Scraped weather data from Meteorological Service Singapore stored in Climate_Data_2015_2024.csv .\nWeather Station records from weather.gov.sg, stored in Station_Records.csv ."
  },
  {
    "objectID": "WebScraping/Data_Preparation.html#daily-weather-records",
    "href": "WebScraping/Data_Preparation.html#daily-weather-records",
    "title": "Data Preparation",
    "section": "3.1 Daily Weather Records",
    "text": "3.1 Daily Weather Records\nFirst we read in the daily weather records scraped from weather.gov.sg into tibble dataframe climate_raw using read_csv() .\n\nclimate_raw = read_csv(\"data/climate_historical_daily_records/Climate_Data_2015_2024.csv\")\n\nNext we check if the scraped data contains any duplicate.\n\nduplicate &lt;- climate_raw %&gt;% \n  group_by_all() %&gt;% \n  filter(n()&gt;1) %&gt;% \n  ungroup()\n  \nduplicate\n\n# A tibble: 0 × 13\n# ℹ 13 variables: Station &lt;chr&gt;, Year &lt;dbl&gt;, Month &lt;dbl&gt;, Day &lt;dbl&gt;,\n#   Daily Rainfall Total (mm) &lt;dbl&gt;, Highest 30 min Rainfall (mm) &lt;dbl&gt;,\n#   Highest 60 min Rainfall (mm) &lt;dbl&gt;, Highest 120 min Rainfall (mm) &lt;dbl&gt;,\n#   Mean Temperature (Celsius) &lt;dbl&gt;, Maximum Temperature (Celsius) &lt;dbl&gt;,\n#   Minimum Temperature (Celsius) &lt;dbl&gt;, Mean Wind Speed (km/h) &lt;dbl&gt;,\n#   Max Wind Speed (km/h) &lt;dbl&gt;\n\n\nThe output shows there is no duplicates.\nThe below code chunk uses summary() to have an overview of the scraped dataset.\n\nsummary(climate_raw)\n\n   Station               Year          Month             Day       \n Length:192483      Min.   :2015   Min.   : 1.000   Min.   : 1.00  \n Class :character   1st Qu.:2017   1st Qu.: 3.000   1st Qu.: 8.00  \n Mode  :character   Median :2019   Median : 6.000   Median :16.00  \n                    Mean   :2019   Mean   : 6.485   Mean   :15.73  \n                    3rd Qu.:2022   3rd Qu.: 9.000   3rd Qu.:23.00  \n                    Max.   :2024   Max.   :12.000   Max.   :31.00  \n                                                                   \n Daily Rainfall Total (mm) Highest 30 min Rainfall (mm)\n Min.   :  0.000           Min.   : 0.000              \n 1st Qu.:  0.000           1st Qu.: 0.000              \n Median :  0.200           Median : 0.200              \n Mean   :  6.672           Mean   : 3.968              \n 3rd Qu.:  6.600           3rd Qu.: 4.200              \n Max.   :247.200           Max.   :71.800              \n NA's   :4921              NA's   :12754               \n Highest 60 min Rainfall (mm) Highest 120 min Rainfall (mm)\n Min.   :  0.000              Min.   :  0.000              \n 1st Qu.:  0.000              1st Qu.:  0.000              \n Median :  0.200              Median :  0.200              \n Mean   :  4.939              Mean   :  5.639              \n 3rd Qu.:  4.800              3rd Qu.:  5.600              \n Max.   :103.100              Max.   :148.600              \n NA's   :12811                NA's   :12808                \n Mean Temperature (Celsius) Maximum Temperature (Celsius)\n Min.   :22.20              Min.   :22.80                \n 1st Qu.:27.30              1st Qu.:30.90                \n Median :28.10              Median :32.00                \n Mean   :28.05              Mean   :31.85                \n 3rd Qu.:28.90              3rd Qu.:33.00                \n Max.   :31.70              Max.   :38.00                \n NA's   :128350             NA's   :124311               \n Minimum Temperature (Celsius) Mean Wind Speed (km/h) Max Wind Speed (km/h)\n Min.   : 0.00                 Min.   : 0.40          Min.   :  3.70       \n 1st Qu.:24.30                 1st Qu.: 5.70          1st Qu.: 26.60       \n Median :25.30                 Median : 7.60          Median : 31.50       \n Mean   :25.39                 Mean   : 8.48          Mean   : 32.92       \n 3rd Qu.:26.40                 3rd Qu.:10.40          3rd Qu.: 37.40       \n Max.   :34.70                 Max.   :66.60          Max.   :138.60       \n NA's   :124342                NA's   :125214         NA's   :124380       \n\n\nThe output shows there are many null values, while the min max range of all weather measurements are in the normal range."
  },
  {
    "objectID": "WebScraping/Data_Preparation.html#weather-station-records",
    "href": "WebScraping/Data_Preparation.html#weather-station-records",
    "title": "Data Preparation",
    "section": "3.2 Weather Station Records",
    "text": "3.2 Weather Station Records\nNext we read in the stations details to retrieve station types and coordinates. For our Shiny application, we focus solely on Full AWS stations, as they provide comprehensive data across all weather parameters. Other station types, such as Closed Stations and Daily Rainfall Stations (which only record rainfall metrics), are excluded from further analysis.\n\n# Read station metadata and filter for Full AWS stations\nstation = read_csv(\"data/Station_Records.csv\") |&gt; \n  filter(Station_Type == \"Full AWS Station\")\n\nThe below code chunk checks for duplicate.\n\nduplicate &lt;- station %&gt;%    \n  group_by_all() %&gt;%    \n  filter(n()&gt;1) %&gt;%    \n  ungroup()\n\nduplicate\n\n# A tibble: 0 × 5\n# ℹ 5 variables: Station &lt;chr&gt;, code &lt;chr&gt;, Lat &lt;dbl&gt;, Long &lt;dbl&gt;,\n#   Station_Type &lt;chr&gt;\n\n\nThe output shows there is no duplicate."
  },
  {
    "objectID": "WebScraping/Data_Preparation.html#join-station-with-climate-dataframe",
    "href": "WebScraping/Data_Preparation.html#join-station-with-climate-dataframe",
    "title": "Data Preparation",
    "section": "4.1 Join Station with Climate dataframe",
    "text": "4.1 Join Station with Climate dataframe\nFirst we join station with climate_raw dataframe using inner_join() to include only records from active Full AWS Station.\n\n# Join to retain only Full AWS station records\nclimate = inner_join(station,climate_raw, by = \"Station\")\n\nThe below code chunk checks for duplicates in the joined dataframe.\n\nduplicate &lt;- climate %&gt;%    \n  group_by_all() %&gt;%    \n  filter(n()&gt;1) %&gt;%    \n  ungroup()    \n\nduplicate\n\n# A tibble: 0 × 17\n# ℹ 17 variables: Station &lt;chr&gt;, code &lt;chr&gt;, Lat &lt;dbl&gt;, Long &lt;dbl&gt;,\n#   Station_Type &lt;chr&gt;, Year &lt;dbl&gt;, Month &lt;dbl&gt;, Day &lt;dbl&gt;,\n#   Daily Rainfall Total (mm) &lt;dbl&gt;, Highest 30 min Rainfall (mm) &lt;dbl&gt;,\n#   Highest 60 min Rainfall (mm) &lt;dbl&gt;, Highest 120 min Rainfall (mm) &lt;dbl&gt;,\n#   Mean Temperature (Celsius) &lt;dbl&gt;, Maximum Temperature (Celsius) &lt;dbl&gt;,\n#   Minimum Temperature (Celsius) &lt;dbl&gt;, Mean Wind Speed (km/h) &lt;dbl&gt;,\n#   Max Wind Speed (km/h) &lt;dbl&gt;\n\n\nThe output shows there is no duplicate in climate dataframe.\nNext we filter climate dataset for only relevant columns for our weather analysis.\n\n# Select relevant columns\nclimate &lt;- climate |&gt; \n  select(Station, Station_Type, Year, Month, Day,\n         `Daily Rainfall Total (mm)`,\n         `Mean Temperature (Celsius)`,\n         `Maximum Temperature (Celsius)`,\n         `Minimum Temperature (Celsius)`,\n         `Mean Wind Speed (km/h)`)\n\nThe final climate dataframe consists of 10 columns, including the 5 key weather parameters selected for further analysis."
  },
  {
    "objectID": "WebScraping/Data_Preparation.html#missing-rainfall-records",
    "href": "WebScraping/Data_Preparation.html#missing-rainfall-records",
    "title": "Data Preparation",
    "section": "4.2 Missing Rainfall records",
    "text": "4.2 Missing Rainfall records\nNext we check for null records from the key parameter Daily Rainfall Total (mm).\n\n# Count missing values for each Station, Year, and Month \nmissing_rain_counts &lt;- climate %&gt;%   \n  group_by(Station, Year, Month) %&gt;%   \n  summarise(\n    `Missing Daily Rainfall Total` = sum(is.na(`Daily Rainfall Total (mm)`))   ) %&gt;%  \n    # Exclude rows where all missing counts are zero\n  filter(`Missing Daily Rainfall Total` &gt; 0) |&gt;\n  ungroup()\n\n\n# Count the number of months per station where missing days exceed 15 \nmissing_rain_summary &lt;- missing_rain_counts %&gt;%   \n  filter(`Missing Daily Rainfall Total` &gt;= 15) %&gt;%   \n  group_by(Station, Year) %&gt;%   \n  summarise(Count_Months = n()) %&gt;%   \n  arrange(Year)|&gt;   \n  pivot_wider(names_from = Year, values_from = Count_Months) |&gt;   \n  ungroup()\n\nThe output reveals 7 stations with ≥15 days of missing Daily Rainfall Total (mm) in more than one month over the years. Semakau Island station has a full year of missing data in 2019, while 2015–2017 period shows a high prevalence of missing data across stations."
  },
  {
    "objectID": "WebScraping/Data_Preparation.html#missing-temperature-records",
    "href": "WebScraping/Data_Preparation.html#missing-temperature-records",
    "title": "Data Preparation",
    "section": "4.3 Missing Temperature Records",
    "text": "4.3 Missing Temperature Records\nWe carry out the same check for Mean Temperature (Celsius).\n\n# Count missing values for each Station, Year, and Month \nmissing_temp_counts &lt;- climate %&gt;%   \n  group_by(Station, Year, Month) %&gt;%   \n  summarise(     \n    `Missing Mean Temperature` = sum(is.na(`Mean Temperature (Celsius)`))) %&gt;%   \n  # Exclude rows where all missing counts are zero\n  filter(`Missing Mean Temperature` &gt; 0) |&gt;\n  ungroup()\n\n\n# Count the number of months per station where missing days exceed 15 \nmissing_temp_summary &lt;- missing_temp_counts %&gt;%    \n  filter(`Missing Mean Temperature` &gt;= 15) %&gt;%   \n  group_by(Station, Year) %&gt;%   \n  summarise(Count_Months = n()) %&gt;%   \n  arrange(Year)|&gt;   \n  pivot_wider(names_from = Year, values_from = Count_Months) |&gt;   \n  ungroup()\n\nThe same 7 stations with significant missing Daily Rainfall Total (mm) are also among the 15 stations with missing Mean Temperature (Celsius) data, where more than 15 days are missing for certain months. Some stations have full years of missing data, with 2015–2017 particularly shows a high prevalence of missing data across stations."
  },
  {
    "objectID": "WebScraping/Data_Preparation.html#exclude-stations-with-many-missing-records",
    "href": "WebScraping/Data_Preparation.html#exclude-stations-with-many-missing-records",
    "title": "Data Preparation",
    "section": "4.4 Exclude stations with many missing records",
    "text": "4.4 Exclude stations with many missing records\nGiven the extensive missing data from 2015–2017, we will retain data from 2018 onwards. For each station, we will count the total number of months with more than 15 days missing data across the years and flag stations with more than 3 missing months. Those stations will be excluded from the main climate dataset.\n\nfilter_invalid_stations &lt;- function(summary_df, from_year = 2018) {\n  # Get only year columns ≥ from_year\n  year_cols &lt;- summary_df |&gt; \n    select(where(is.numeric)) |&gt; \n    select(matches(\"^[0-9]{4}$\")) |&gt; \n    select(as.character(from_year):last_col()) |&gt; \n    colnames()\n\n  summary_df |&gt; \n    rowwise() |&gt; \n    mutate(total_flagged_months = sum(c_across(all_of(year_cols)), na.rm = TRUE)) |&gt; \n    filter(total_flagged_months &gt;= 3) |&gt; \n    pull(Station)\n}\n\n\n# Get invalid stations (stations to exclude)\ninvalid_rain_stations &lt;- filter_invalid_stations(missing_rain_summary)\ninvalid_temp_stations &lt;- filter_invalid_stations(missing_temp_summary)\n\n\n# Combine all stations to exclude\nstations_to_exclude &lt;- union(invalid_rain_stations, invalid_temp_stations) \n\nThe above 5 stations will be excluded. The below code chunk applies this filter on the climate dataframe.\n\n# Now filter the full dataset to only include stations from 2018-2024\nclimate_final &lt;- climate |&gt; \n  filter(!(Station %in% stations_to_exclude), Year &gt;= 2018, Year &lt;= 2024)\n\nsummary(climate_final)\n\n   Station          Station_Type            Year          Month       \n Length:38186       Length:38186       Min.   :2018   Min.   : 1.000  \n Class :character   Class :character   1st Qu.:2019   1st Qu.: 4.000  \n Mode  :character   Mode  :character   Median :2021   Median : 7.000  \n                                       Mean   :2021   Mean   : 6.529  \n                                       3rd Qu.:2023   3rd Qu.:10.000  \n                                       Max.   :2024   Max.   :12.000  \n                                                                      \n      Day        Daily Rainfall Total (mm) Mean Temperature (Celsius)\n Min.   : 1.00   Min.   :  0.000           Min.   :22.20             \n 1st Qu.: 8.00   1st Qu.:  0.000           1st Qu.:27.30             \n Median :16.00   Median :  0.200           Median :28.10             \n Mean   :15.73   Mean   :  6.868           Mean   :28.05             \n 3rd Qu.:23.00   3rd Qu.:  6.600           3rd Qu.:28.90             \n Max.   :31.00   Max.   :210.600           Max.   :31.70             \n                 NA's   :260               NA's   :571               \n Maximum Temperature (Celsius) Minimum Temperature (Celsius)\n Min.   :22.80                 Min.   :20.40                \n 1st Qu.:30.80                 1st Qu.:24.40                \n Median :32.00                 Median :25.40                \n Mean   :31.79                 Mean   :25.46                \n 3rd Qu.:33.00                 3rd Qu.:26.50                \n Max.   :38.00                 Max.   :29.70                \n NA's   :483                   NA's   :487                  \n Mean Wind Speed (km/h)\n Min.   : 0.400        \n 1st Qu.: 5.600        \n Median : 7.600        \n Mean   : 8.474        \n 3rd Qu.:10.400        \n Max.   :31.300        \n NA's   :1701          \n\n\nclimate_final is the filtered dataset obtained. Below is the list of the final 15 AWS stations that we will be focusing our analysis on.\n\nclimate_final %&gt;% \n  distinct(Station) %&gt;% \n  arrange(Station) %&gt;% \n  mutate(Station_ID = row_number())\n\n# A tibble: 15 × 2\n   Station               Station_ID\n   &lt;chr&gt;                      &lt;int&gt;\n 1 Admiralty                      1\n 2 Ang Mo Kio                     2\n 3 Changi                         3\n 4 Choa Chu Kang (South)          4\n 5 Clementi                       5\n 6 East Coast Parkway             6\n 7 Jurong (West)                  7\n 8 Jurong Island                  8\n 9 Newton                         9\n10 Pasir Panjang                 10\n11 Paya Lebar                    11\n12 Pulau Ubin                    12\n13 Sentosa Island                13\n14 Tai Seng                      14\n15 Tuas South                    15"
  },
  {
    "objectID": "WebScraping/Data_Preparation.html#replacing-missing-values-using-sma-5-days",
    "href": "WebScraping/Data_Preparation.html#replacing-missing-values-using-sma-5-days",
    "title": "Data Preparation",
    "section": "4.5 Replacing Missing Values using SMA 5 days",
    "text": "4.5 Replacing Missing Values using SMA 5 days\nThe below code chunk counts the number of missing values in each column of climate_final.\n\nclimate_final %&gt;% \n  summarise(across(where(is.numeric), ~sum(is.na(.)), .names = \"missing_{.col}\"))\n\n# A tibble: 1 × 8\n  missing_Year missing_Month missing_Day `missing_Daily Rainfall Total (mm)`\n         &lt;int&gt;         &lt;int&gt;       &lt;int&gt;                               &lt;int&gt;\n1            0             0           0                                 260\n# ℹ 4 more variables: `missing_Mean Temperature (Celsius)` &lt;int&gt;,\n#   `missing_Maximum Temperature (Celsius)` &lt;int&gt;,\n#   `missing_Minimum Temperature (Celsius)` &lt;int&gt;,\n#   `missing_Mean Wind Speed (km/h)` &lt;int&gt;\n\n\nThe output reveals multiple missing values across the five weather parameters. To address this, we will first apply a 5-day backward moving average for imputation. However, for cases where this method cannot be applied (e.g., missing values at the beginning of the time series), we will use a 5-day forward moving average as a fallback.\n\n# === Load dataset ===\nclimate &lt;- climate_final\noriginal &lt;- climate\n\n# === Columns to impute ===\nimpute_cols &lt;- c(\"Daily Rainfall Total (mm)\",\n                 \"Mean Temperature (Celsius)\",\n                 \"Maximum Temperature (Celsius)\",\n                 \"Minimum Temperature (Celsius)\",\n                 \"Mean Wind Speed (km/h)\")\n\n# === Backward SMA-5 for first 4 rows ===\n# === Backward SMA-5 (recursive fill for rows 4 to 1) ===\nfor (i in 4:1) {\n  window &lt;- climate[(i + 1):(i + 5), impute_cols]\n  sma_values &lt;- colMeans(window, na.rm = TRUE) %&gt;% round(1)\n  climate[i, impute_cols] &lt;- as.list(sma_values)\n}\n\n\n# === Forward SMA-5 for all other NAs ===\nfor (col in impute_cols) {\n  na_indices &lt;- which(is.na(climate[[col]]))\n  for (idx in na_indices) {\n    if (idx &gt;= 5) {\n      sma_val &lt;- mean(climate[[col]][(idx - 5):(idx - 1)], na.rm = TRUE) %&gt;% round(1)\n      if (!is.nan(sma_val)) {\n        climate[[col]][idx] &lt;- sma_val\n      }\n    }\n  }\n}\n\n# === Save updated CSV ===\nwrite_csv(climate, \"data/climate_historical_daily_records/climate_final_2018_2024.csv\")\n\nThe final prepared dataset for our analysis is saved as climate_final_2018_2024.csv with no missing data.\nThe below code chunk reads the final dataset from climate_final_2018_2024.csvfor further analysis.\n\nclimate = read_csv('data/climate_historical_daily_records/climate_final_2018_2024.csv')\n\nWe verify the final climate dataframe for missing data using below code chunk. The output confirms that all missing values have been successfully imputed.\n\nclimate %&gt;% \n  summarise(across(where(is.numeric), ~sum(is.na(.)), .names = \"missing_{.col}\"))\n\n# A tibble: 1 × 8\n  missing_Year missing_Month missing_Day `missing_Daily Rainfall Total (mm)`\n         &lt;int&gt;         &lt;int&gt;       &lt;int&gt;                               &lt;int&gt;\n1            0             0           0                                   0\n# ℹ 4 more variables: `missing_Mean Temperature (Celsius)` &lt;int&gt;,\n#   `missing_Maximum Temperature (Celsius)` &lt;int&gt;,\n#   `missing_Minimum Temperature (Celsius)` &lt;int&gt;,\n#   `missing_Mean Wind Speed (km/h)` &lt;int&gt;\n\n\nThe below code chunk provides a summary of the imputed climate dataframe.\n\nsummary(climate)\n\n   Station          Station_Type            Year          Month       \n Length:38186       Length:38186       Min.   :2018   Min.   : 1.000  \n Class :character   Class :character   1st Qu.:2019   1st Qu.: 4.000  \n Mode  :character   Mode  :character   Median :2021   Median : 7.000  \n                                       Mean   :2021   Mean   : 6.529  \n                                       3rd Qu.:2023   3rd Qu.:10.000  \n                                       Max.   :2024   Max.   :12.000  \n      Day        Daily Rainfall Total (mm) Mean Temperature (Celsius)\n Min.   : 1.00   Min.   :  0.000           Min.   :22.20             \n 1st Qu.: 8.00   1st Qu.:  0.000           1st Qu.:27.20             \n Median :16.00   Median :  0.200           Median :28.10             \n Mean   :15.73   Mean   :  6.888           Mean   :28.04             \n 3rd Qu.:23.00   3rd Qu.:  6.600           3rd Qu.:28.90             \n Max.   :31.00   Max.   :210.600           Max.   :31.70             \n Maximum Temperature (Celsius) Minimum Temperature (Celsius)\n Min.   :22.80                 Min.   :20.40                \n 1st Qu.:30.80                 1st Qu.:24.40                \n Median :32.00                 Median :25.40                \n Mean   :31.79                 Mean   :25.46                \n 3rd Qu.:33.00                 3rd Qu.:26.50                \n Max.   :38.00                 Max.   :29.70                \n Mean Wind Speed (km/h)\n Min.   : 0.400        \n 1st Qu.: 5.700        \n Median : 7.600        \n Mean   : 8.605        \n 3rd Qu.:10.600        \n Max.   :31.300"
  }
]